{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2763cbb4",
   "metadata": {},
   "source": [
    "# Analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import pymongo as pm\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"\"))))\n",
    "import cabutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285cb1d",
   "metadata": {},
   "source": [
    "# create relevant project subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create relevant project subdirs\n",
    "proj_dir = os.path.abspath('..')\n",
    "analysis_dir =  os.path.join(proj_dir,'analysis')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "plots_dir = os.path.join(results_dir,'plots')\n",
    "\n",
    "def makedir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return\n",
    " \n",
    "makedir(results_dir)\n",
    "makedir(csv_dir)\n",
    "makedir(plots_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa6356",
   "metadata": {},
   "source": [
    "# establish connection to mongo and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the relevant variables\n",
    "dbname = '' ## which database are we using, e.g. BACH?\n",
    "colname = '' ## which collection inside this database, e.g. dominoes?\n",
    "iterationName = '' ## which iterations do we want to analyze, e.g. iter1?\n",
    "\n",
    "# establish connection to mongo\n",
    "conn = cabutils.get_db_connection()\n",
    "db = conn[dbname] \n",
    "coll = db[colname]\n",
    "## fetch all records from this iterationName\n",
    "K = coll.find({'iterationName':iterationName})\n",
    "li = list(K)\n",
    "_M = pd.DataFrame(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e42171",
   "metadata": {},
   "source": [
    "# apply data exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get unique gameIDs for completed games only\n",
    "completed_games = []\n",
    "for gameID in _M['gameID'].unique():\n",
    "    ## check if we have a survey event for the gameID\n",
    "    events = list(_M[_M['gameID'] == gameID]['eventType'])\n",
    "    if (\"survey_data\" in events): completed_games.append(gameID)\n",
    "\n",
    "print(\"We have\",len(completed_games),\"completed unique games.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d08dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter on complete games \n",
    "M = _M[_M['gameID'].isin(completed_games)]\n",
    "\n",
    "## separate into T (trials) and S (survey) dataframes\n",
    "T_train = M[M['eventType']=='training_trials']\n",
    "T_test = M[M['eventType']=='test_trials']\n",
    "T = pd.concat([T_train, T_test], ignore_index=True, sort=False)\n",
    "S = M[M['eventType']=='survey_data']\n",
    "\n",
    "## make sure that all the games in T are also in S (sanity check)\n",
    "Tgames = list(np.unique(T['gameID'].values))\n",
    "Sgames = list(np.unique(S['gameID'].values))\n",
    "assert len(np.intersect1d(Tgames,Sgames))==len(Tgames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5500138",
   "metadata": {},
   "source": [
    "# drop the sensitive information and save to csv locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea72aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANONYMIZE DATAFRAMES: drop ProlificID & any other potentially identifying info from T & S\n",
    "T = T.drop(columns=['ProlificID'])\n",
    "S = S.drop(columns=['ProlificID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save out to file \n",
    "S.to_csv(os.path.join(csv_dir, '{}_{}_survey.csv'.format(colname, iterationName)),index=False)\n",
    "T.to_csv(os.path.join(csv_dir, '{}_{}_trials.csv'.format(colname, iterationName)),index=False)\n",
    "print('Saved successfully to file!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81767db7",
   "metadata": {},
   "source": [
    "# visualize the data and do the analysis you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
